{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow Version: 9.4.0\n"
     ]
    }
   ],
   "source": [
    "# check Pillow version number\n",
    "import PIL\n",
    "print('Pillow Version:', PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG\n",
      "RGB\n",
      "(499, 375)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('data/train/dog.10025.jpg')\n",
    "\n",
    "print(image.format)\n",
    "print(image.mode)\n",
    "print(image.size)\n",
    "\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269, 259, 3)\n",
      "None\n",
      "RGB\n",
      "(259, 269)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "imdata = np.asarray(image)\n",
    "\n",
    "print(imdata.shape)\n",
    "\n",
    "image2 = Image.fromarray(imdata)\n",
    "\n",
    "print(image2.format)\n",
    "print(image2.mode)\n",
    "print(image2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps\n",
    "\n",
    "def padding(image, expected_size):\n",
    "    delta_width = expected_size[0] - image.size[0]\n",
    "    delta_height = expected_size[1] - image.size[1]\n",
    "\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "\n",
    "    padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    return ImageOps.expand(image, padding)\n",
    "\n",
    "def resize_with_padding(image, expected_size):\n",
    "    image.thumbnail((expected_size[0], expected_size[1]))\n",
    "\n",
    "    delta_width = expected_size[0] - image.size[0]\n",
    "    delta_height = expected_size[1] - image.size[1]\n",
    "\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "\n",
    "    padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    return ImageOps.expand(image, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> loaded 200 images\n",
      "> loaded 400 images\n",
      "> loaded 600 images\n",
      "> loaded 800 images\n",
      "> loaded 1000 images\n",
      "> loaded 1200 images\n",
      "> loaded 1400 images\n",
      "> loaded 1600 images\n",
      "> loaded 1800 images\n",
      "> loaded 2000 images\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "import matplotlib.image\n",
    "# import matplotlib.image as img\n",
    "\n",
    "loaded_images = list()\n",
    "loaded_labels = list()\n",
    "count = 0\n",
    "for filename in listdir('data/train/'):\n",
    "    if filename.find('cat') != -1:\n",
    "        loaded_labels.append('cat')\n",
    "    else:\n",
    "        loaded_labels.append('dog')\n",
    "\n",
    "    img = Image.open('data/train/' + filename)\n",
    "    resized_img = resize_with_padding(img, (100, 100))\n",
    "\n",
    "    img_data = np.asarray(resized_img)\n",
    "    loaded_images.append(img_data)\n",
    "    count += 1\n",
    "    if count % 200 == 0:\n",
    "        print(\"> loaded %d images\" % (count))\n",
    "    # print('> loaded %s %s' % (filename, img_data.shape))\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(loaded_labels[100])\n",
    "test_img = Image.fromarray(loaded_images[100])\n",
    "test_img.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "data_set = list(zip(loaded_images, loaded_labels))\n",
    "print(type(data_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "# print(data_set[0])\n",
    "print(data_set[0][0].shape)\n",
    "print(type(data_set[0][0]))\n",
    "print(data_set[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_set, columns= ['Image', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image    2000\n",
       "Label    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat    1001\n",
       "dog     999\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoded Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Encoded Label\n",
       "count    2000.000000\n",
       "mean        0.499500\n",
       "std         0.500125\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(df['Label'].values)\n",
    "label_bool = list()\n",
    "for label in df['Label'].values:\n",
    "    label_bool.append(0 if label == 'cat' else 1)\n",
    "df[\"Encoded Label\"] = label_bool\n",
    "df.drop('Label', axis=1)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=84)\n",
    "for train_index, test_index in split.split(df, df['Encoded Label']):\n",
    "    train_set = df.loc[train_index]\n",
    "    test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    801\n",
      "1    799\n",
      "Name: Encoded Label, dtype: int64\n",
      "       Encoded Label\n",
      "count     400.000000\n",
      "mean        0.500000\n",
      "std         0.500626\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.500000\n",
      "75%         1.000000\n",
      "max         1.000000\n"
     ]
    }
   ],
   "source": [
    "print(train_set['Encoded Label'].value_counts())\n",
    "# print(test_set['Image'].value_counts())\n",
    "print(test_set.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(df[\u001b[39m'\u001b[39;49m\u001b[39mImage\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "torch_tensor = torch.from_numpy(df['Image'].values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DataFrame to PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[39m=\u001b[39m TensorDataset(df[\u001b[39m'\u001b[39;49m\u001b[39mImage\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues, df[\u001b[39m'\u001b[39;49m\u001b[39mEncoded Label\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataset.py:192\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39;49m(tensors[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39m==\u001b[39;49m tensor\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m tensor \u001b[39min\u001b[39;49;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/utils/data/dataset.py:192\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtensors: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(tensors[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m) \u001b[39m==\u001b[39m tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors), \u001b[39m\"\u001b[39m\u001b[39mSize mismatch between tensors\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtensors \u001b[39m=\u001b[39m tensors\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "train_dataset = TensorDataset(df['Image'].values, df['Encoded Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogData(Dataset):\n",
    "    def __init__(self, df, data_colname, label_colname):\n",
    "        self.X = torch.tensor(df[data_colname])\n",
    "        self.y = torch.tensor(df[label_colname])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 3",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m catdog_train_set \u001b[39m=\u001b[39m CatDogData(train_set, \u001b[39m'\u001b[39;49m\u001b[39mImage\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mLabel\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(\n\u001b[1;32m      3\u001b[0m     dataset\u001b[39m=\u001b[39mcatdog_train_set,\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m      5\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m catdog_test_set \u001b[39m=\u001b[39m CatDogData(test_set, \u001b[39m'\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLabel\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m, in \u001b[0;36mCatDogData.__init__\u001b[0;34m(self, df, data_colname, label_colname)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, df, data_colname, label_colname):\n\u001b[0;32m----> 3\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(df[data_colname])\n\u001b[1;32m      4\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(df[label_colname])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "# catdog_train_set = CatDogData(train_set, 'Image', 'Label')\n",
    "# train_dataloader = DataLoader(\n",
    "#     dataset=catdog_train_set,\n",
    "#     batch_size=10,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "# catdog_test_set = CatDogData(test_set, 'Image', 'Label')\n",
    "# test_dataloader = DataLoader(\n",
    "#     dataset=catdog_test_set,\n",
    "#     batch_size=10,\n",
    "#     shuffle=False\n",
    "# )\n",
    "\n",
    "# labels = ('cat', 'dog')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # [100, 100, 3]\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=6,\n",
    "                kernel_size=5\n",
    "            ),\n",
    "            # [96, 96, 6]\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=4,\n",
    "                stride=4\n",
    "            ),\n",
    "            # [24, 24, 6]\n",
    "            nn.Conv2d(\n",
    "                in_channels=6,\n",
    "                out_channels=12,\n",
    "                kernel_size=5\n",
    "            ),\n",
    "            # [20, 20, 12]\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=4,\n",
    "                stride=4\n",
    "            ),\n",
    "            # [5, 5, 12]\n",
    "            nn.Flatten(),\n",
    "            # [5*5*12, 1]\n",
    "            nn.Linear(\n",
    "                in_features=5*5*12, \n",
    "                out_features=120\n",
    "            ),\n",
    "            # [1, 120]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                in_features=120, \n",
    "                out_features=30\n",
    "            ),\n",
    "            # [1, 30]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(\n",
    "                in_features=30, \n",
    "                out_features=2\n",
    "            )\n",
    "            # [1, 2]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
