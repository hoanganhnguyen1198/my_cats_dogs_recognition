{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'data/train/')\n",
    "data_path_cat = data_path + 'cat/'\n",
    "data_path_dog = data_path + 'dog/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(image, expected_size):\n",
    "    delta_width = expected_size[0] - image.size[0]\n",
    "    delta_height = expected_size[1] - image.size[1]\n",
    "\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "\n",
    "    padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    return ImageOps.expand(image, padding)\n",
    "\n",
    "def resize_with_padding(image, expected_size):\n",
    "    image.thumbnail((expected_size[0], expected_size[1]))\n",
    "\n",
    "    delta_width = expected_size[0] - image.size[0]\n",
    "    delta_height = expected_size[1] - image.size[1]\n",
    "\n",
    "    pad_width = delta_width // 2\n",
    "    pad_height = delta_height // 2\n",
    "\n",
    "    padding = (pad_width, pad_height, delta_width - pad_width, delta_height - pad_height)\n",
    "    return ImageOps.expand(image, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in listdir(data_path_cat):\n",
    "    img = Image.open(data_path_cat + filename)\n",
    "    resized_img = resize_with_padding(img, IMAGE_SIZE)\n",
    "    resized_img.save(data_path_cat + filename)\n",
    "for filename in listdir(data_path_dog):\n",
    "    img = Image.open(data_path_dog + filename)\n",
    "    resized_img = resize_with_padding(img, IMAGE_SIZE)\n",
    "    resized_img.save(data_path_dog + filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 files belonging to 2 classes.\n",
      "Using 9600 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 13:02:13.581593: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=84,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 files belonging to 2 classes.\n",
      "Using 2400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=84,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
